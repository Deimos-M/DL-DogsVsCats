{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model using bottleneck features of a pre-trained network \n",
    "\n",
    "* https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipul\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as npp\n",
    "import math\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "train_data_dir = r\"C:\\Users\\**\\Desktop\\jupyter\\DL\\CNN egs\\Data\\train\"\n",
    "validation_data_dir = r\"C:\\Users\\**\\Desktop\\jupyter\\DL\\CNN egs\\Data\\validation\"\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 600\n",
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen= ImageDataGenerator(rescale=1. /255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#downloading and building vgg16 model\n",
    "vgg16_model=applications.VGG16(include_top=False)\n",
    "#only downloading upto the dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None, # this means our generator will only yield batches of data, not labels\n",
    "        shuffle=False) # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n",
    "\n",
    "#the predict_generator method returns the output of a model(features), passing a generator that yields the batches of numpy data.\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "bottleneck_features_train = vgg16_model.predict_generator(generator, predict_size_train)\n",
    "\n",
    "npp.save(open('bottleneck_features_vgg16_train.npy', 'wb'), bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "bottleneck_features_validation = vgg16_model.predict_generator(generator, predict_size_validation)\n",
    "\n",
    "npp.save(open('bottleneck_features_vgg16_validation.npy', 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = npp.load(open('bottleneck_features_vgg16_train.npy', 'rb'))\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "train_labels = npp.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_data = npp.load(open('bottleneck_features_vgg16_validation.npy', 'rb'))\n",
    "validation_labels = npp.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 8,389,121\n",
      "Trainable params: 8,389,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#completing the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 600 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 4.3670 - acc: 0.6290 - val_loss: 0.7235 - val_acc: 0.8717\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 1.0217 - acc: 0.8165 - val_loss: 0.6486 - val_acc: 0.7983\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.5618 - acc: 0.8210 - val_loss: 0.3124 - val_acc: 0.8883\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2957 - acc: 0.8770 - val_loss: 0.2822 - val_acc: 0.9050\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.4015 - acc: 0.8745 - val_loss: 0.2990 - val_acc: 0.8833\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2996 - acc: 0.8935 - val_loss: 0.2581 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2319 - acc: 0.9190 - val_loss: 0.2696 - val_acc: 0.9017\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2067 - acc: 0.9270 - val_loss: 0.2874 - val_acc: 0.9017\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1839 - acc: 0.9445 - val_loss: 0.3680 - val_acc: 0.8917\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2301 - acc: 0.9360 - val_loss: 0.3117 - val_acc: 0.8917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2558ede3f98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('2ndconvnet_bottleneck_features_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As observed the validation accuracy is jumped from 65%(1st_convnet) to **89%** by simply using the pretrained weights of vgg16 model trained on ImageNet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
